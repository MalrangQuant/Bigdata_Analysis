{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "pd.set_option('max_rows', 300)\n",
    "pd.set_option('max_columns', 300)\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from enum import Enum\n",
    "from joblib import delayed, Parallel\n",
    "from contextlib import contextmanager\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "@contextmanager\n",
    "def timer(name: str):\n",
    "    s = time.time()\n",
    "    yield\n",
    "    elapsed = time.time() - s\n",
    "    print(f'[{name}] {elapsed: .3f}sec')\n",
    "    \n",
    "def print_trace(name: str = ''):\n",
    "    print(f'ERROR RAISED IN {name or \"anonymous\"}')\n",
    "    print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.001445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.002168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.002195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0.001747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock_id  time_id    target\n",
       "0         0        5  0.004136\n",
       "1         0       11  0.001445\n",
       "2         0       16  0.002168\n",
       "3         0       31  0.002195\n",
       "4         0       62  0.001747"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_DIR = './Data/optiver-realized-volatility-prediction/'\n",
    "\n",
    "train = pd.read_csv(PATH_DIR + 'train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>bid_price1</th>\n",
       "      <th>ask_price1</th>\n",
       "      <th>bid_price2</th>\n",
       "      <th>ask_price2</th>\n",
       "      <th>bid_size1</th>\n",
       "      <th>ask_size1</th>\n",
       "      <th>bid_size2</th>\n",
       "      <th>ask_size2</th>\n",
       "      <th>stock_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.001422</td>\n",
       "      <td>1.002301</td>\n",
       "      <td>1.001370</td>\n",
       "      <td>1.002353</td>\n",
       "      <td>3</td>\n",
       "      <td>226</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.001422</td>\n",
       "      <td>1.002301</td>\n",
       "      <td>1.001370</td>\n",
       "      <td>1.002353</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.001422</td>\n",
       "      <td>1.002301</td>\n",
       "      <td>1.001370</td>\n",
       "      <td>1.002405</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1.001422</td>\n",
       "      <td>1.002301</td>\n",
       "      <td>1.001370</td>\n",
       "      <td>1.002405</td>\n",
       "      <td>3</td>\n",
       "      <td>126</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1.001422</td>\n",
       "      <td>1.002301</td>\n",
       "      <td>1.001370</td>\n",
       "      <td>1.002405</td>\n",
       "      <td>3</td>\n",
       "      <td>126</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>5</td>\n",
       "      <td>585</td>\n",
       "      <td>1.003129</td>\n",
       "      <td>1.003749</td>\n",
       "      <td>1.003025</td>\n",
       "      <td>1.003801</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>5</td>\n",
       "      <td>586</td>\n",
       "      <td>1.003129</td>\n",
       "      <td>1.003749</td>\n",
       "      <td>1.002612</td>\n",
       "      <td>1.003801</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>5</td>\n",
       "      <td>587</td>\n",
       "      <td>1.003129</td>\n",
       "      <td>1.003749</td>\n",
       "      <td>1.003025</td>\n",
       "      <td>1.003801</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>5</td>\n",
       "      <td>588</td>\n",
       "      <td>1.003129</td>\n",
       "      <td>1.003749</td>\n",
       "      <td>1.002612</td>\n",
       "      <td>1.003801</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>5</td>\n",
       "      <td>593</td>\n",
       "      <td>1.003129</td>\n",
       "      <td>1.003749</td>\n",
       "      <td>1.003025</td>\n",
       "      <td>1.003801</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>302 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     time_id  seconds_in_bucket  bid_price1  ask_price1  bid_price2  \\\n",
       "0          5                  0    1.001422    1.002301    1.001370   \n",
       "1          5                  1    1.001422    1.002301    1.001370   \n",
       "2          5                  5    1.001422    1.002301    1.001370   \n",
       "3          5                  6    1.001422    1.002301    1.001370   \n",
       "4          5                  7    1.001422    1.002301    1.001370   \n",
       "..       ...                ...         ...         ...         ...   \n",
       "297        5                585    1.003129    1.003749    1.003025   \n",
       "298        5                586    1.003129    1.003749    1.002612   \n",
       "299        5                587    1.003129    1.003749    1.003025   \n",
       "300        5                588    1.003129    1.003749    1.002612   \n",
       "301        5                593    1.003129    1.003749    1.003025   \n",
       "\n",
       "     ask_price2  bid_size1  ask_size1  bid_size2  ask_size2  stock_id  \n",
       "0      1.002353          3        226          2        100         0  \n",
       "1      1.002353          3        100          2        100         0  \n",
       "2      1.002405          3        100          2        100         0  \n",
       "3      1.002405          3        126          2        100         0  \n",
       "4      1.002405          3        126          2        100         0  \n",
       "..          ...        ...        ...        ...        ...       ...  \n",
       "297    1.003801        100          3         26          3         0  \n",
       "298    1.003801        100          3          2          3         0  \n",
       "299    1.003801        100          3         26          3         0  \n",
       "300    1.003801        100          3          2          3         0  \n",
       "301    1.003801        100          3         26          3         0  \n",
       "\n",
       "[302 rows x 11 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_example = pd.read_parquet(PATH_DIR + 'book_train.parquet/stock_id=0')\n",
    "trade_example = pd.read_parquet(PATH_DIR + 'trade_train.parquet/stock_id=0')\n",
    "\n",
    "stock_id = 0\n",
    "book_example = book_example[book_example['time_id']==5]\n",
    "trade_example = trade_example[trade_example['time_id']==5]\n",
    "\n",
    "book_example['stock_id'] = stock_id\n",
    "trade_example['stock_id'] = stock_id\n",
    "\n",
    "book_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>bid_price1</th>\n",
       "      <th>ask_price1</th>\n",
       "      <th>bid_price2</th>\n",
       "      <th>ask_price2</th>\n",
       "      <th>bid_size1</th>\n",
       "      <th>ask_size1</th>\n",
       "      <th>bid_size2</th>\n",
       "      <th>ask_size2</th>\n",
       "      <th>stock_id</th>\n",
       "      <th>wap</th>\n",
       "      <th>log_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.001422</td>\n",
       "      <td>1.002301</td>\n",
       "      <td>1.001370</td>\n",
       "      <td>1.002353</td>\n",
       "      <td>3</td>\n",
       "      <td>226</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1.001434</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.001422</td>\n",
       "      <td>1.002301</td>\n",
       "      <td>1.001370</td>\n",
       "      <td>1.002353</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1.001448</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.001422</td>\n",
       "      <td>1.002301</td>\n",
       "      <td>1.001370</td>\n",
       "      <td>1.002405</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1.001448</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1.001422</td>\n",
       "      <td>1.002301</td>\n",
       "      <td>1.001370</td>\n",
       "      <td>1.002405</td>\n",
       "      <td>3</td>\n",
       "      <td>126</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1.001443</td>\n",
       "      <td>-0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1.001422</td>\n",
       "      <td>1.002301</td>\n",
       "      <td>1.001370</td>\n",
       "      <td>1.002405</td>\n",
       "      <td>3</td>\n",
       "      <td>126</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1.001443</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>5</td>\n",
       "      <td>585</td>\n",
       "      <td>1.003129</td>\n",
       "      <td>1.003749</td>\n",
       "      <td>1.003025</td>\n",
       "      <td>1.003801</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.003731</td>\n",
       "      <td>0.000245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>5</td>\n",
       "      <td>586</td>\n",
       "      <td>1.003129</td>\n",
       "      <td>1.003749</td>\n",
       "      <td>1.002612</td>\n",
       "      <td>1.003801</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.003731</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>5</td>\n",
       "      <td>587</td>\n",
       "      <td>1.003129</td>\n",
       "      <td>1.003749</td>\n",
       "      <td>1.003025</td>\n",
       "      <td>1.003801</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.003731</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>5</td>\n",
       "      <td>588</td>\n",
       "      <td>1.003129</td>\n",
       "      <td>1.003749</td>\n",
       "      <td>1.002612</td>\n",
       "      <td>1.003801</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.003731</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>5</td>\n",
       "      <td>593</td>\n",
       "      <td>1.003129</td>\n",
       "      <td>1.003749</td>\n",
       "      <td>1.003025</td>\n",
       "      <td>1.003801</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.003731</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>302 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     time_id  seconds_in_bucket  bid_price1  ask_price1  bid_price2  \\\n",
       "0          5                  0    1.001422    1.002301    1.001370   \n",
       "1          5                  1    1.001422    1.002301    1.001370   \n",
       "2          5                  5    1.001422    1.002301    1.001370   \n",
       "3          5                  6    1.001422    1.002301    1.001370   \n",
       "4          5                  7    1.001422    1.002301    1.001370   \n",
       "..       ...                ...         ...         ...         ...   \n",
       "297        5                585    1.003129    1.003749    1.003025   \n",
       "298        5                586    1.003129    1.003749    1.002612   \n",
       "299        5                587    1.003129    1.003749    1.003025   \n",
       "300        5                588    1.003129    1.003749    1.002612   \n",
       "301        5                593    1.003129    1.003749    1.003025   \n",
       "\n",
       "     ask_price2  bid_size1  ask_size1  bid_size2  ask_size2  stock_id  \\\n",
       "0      1.002353          3        226          2        100         0   \n",
       "1      1.002353          3        100          2        100         0   \n",
       "2      1.002405          3        100          2        100         0   \n",
       "3      1.002405          3        126          2        100         0   \n",
       "4      1.002405          3        126          2        100         0   \n",
       "..          ...        ...        ...        ...        ...       ...   \n",
       "297    1.003801        100          3         26          3         0   \n",
       "298    1.003801        100          3          2          3         0   \n",
       "299    1.003801        100          3         26          3         0   \n",
       "300    1.003801        100          3          2          3         0   \n",
       "301    1.003801        100          3         26          3         0   \n",
       "\n",
       "          wap  log_return  \n",
       "0    1.001434         NaN  \n",
       "1    1.001448    0.000014  \n",
       "2    1.001448    0.000000  \n",
       "3    1.001443   -0.000005  \n",
       "4    1.001443    0.000000  \n",
       "..        ...         ...  \n",
       "297  1.003731    0.000245  \n",
       "298  1.003731    0.000000  \n",
       "299  1.003731    0.000000  \n",
       "300  1.003731    0.000000  \n",
       "301  1.003731    0.000000  \n",
       "\n",
       "[302 rows x 13 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def log_return(list_stock_prices: list) -> list:\n",
    "    return np.log(list_stock_prices).diff()\n",
    "\n",
    "def cal_wap (df: pd.DataFrame) -> pd.Series:\n",
    "    wap = (df['bid_price1'] * df['ask_size1'] +\n",
    "                                df['ask_price1'] * df['bid_size1']) / (\n",
    "                                       df['bid_size1']+ df['ask_size1'])\n",
    "\n",
    "    return wap\n",
    "\n",
    "def realized_volatility (series_log_return):\n",
    "    return np.sqr\n",
    "\n",
    "book_example['wap'] = cal_wap(book_example)\n",
    "book_example['log_return'] = log_return(book_example['wap'])\n",
    "\n",
    "book_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import traceback\n",
    "from contextlib import contextmanager\n",
    "from enum import Enum\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from IPython.display import display\n",
    "\n",
    "from joblib import delayed, Parallel\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "DATA_DIR = './Data'\n",
    "\n",
    "# data configurations\n",
    "USE_PRECOMPUTE_FEATURES = True  # Load precomputed features for train.csv from private dataset (just for speed up)\n",
    "\n",
    "# model & ensemble configurations\n",
    "PREDICT_CNN = True\n",
    "PREDICT_MLP = True\n",
    "PREDICT_GBDT = True\n",
    "PREDICT_TABNET = False\n",
    "\n",
    "GBDT_NUM_MODELS = 5 #3\n",
    "GBDT_LR = 0.02  # 0.1\n",
    "\n",
    "NN_VALID_TH = 0.185\n",
    "NN_MODEL_TOP_N = 3\n",
    "TAB_MODEL_TOP_N = 3\n",
    "ENSEMBLE_METHOD = 'mean'\n",
    "NN_NUM_MODELS = 10\n",
    "TABNET_NUM_MODELS = 5\n",
    "\n",
    "# for saving quota\n",
    "IS_1ST_STAGE = False\n",
    "SHORTCUT_NN_IN_1ST_STAGE = False  # early-stop training to save GPU quota\n",
    "SHORTCUT_GBDT_IN_1ST_STAGE = False\n",
    "MEMORY_TEST_MODE = False\n",
    "\n",
    "# for ablation studies\n",
    "CV_SPLIT = 'time'  # 'time': time-series KFold 'group': GroupKFold by stock-id\n",
    "USE_PRICE_NN_FEATURES = True  # Use nearest neighbor features that rely on tick size\n",
    "USE_VOL_NN_FEATURES = True  # Use nearest neighbor features that can be calculated without tick size\n",
    "USE_SIZE_NN_FEATURES = True  # Use nearest neighbor features that can be calculated without tick size\n",
    "USE_RANDOM_NN_FEATURES = False  # Use random index to aggregate neighbors\n",
    "\n",
    "USE_TIME_ID_NN = True  # Use time-id based neighbors\n",
    "USE_STOCK_ID_NN = True  # Use stock-id based neighbors\n",
    "\n",
    "ENABLE_RANK_NORMALIZATION = True  # Enable rank-normalization\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def timer(name: str):\n",
    "    s = time.time()\n",
    "    yield\n",
    "    elapsed = time.time() - s\n",
    "    print(f'[{name}] {elapsed: .3f}sec')\n",
    "    \n",
    "def print_trace(name: str = ''):\n",
    "    print(f'ERROR RAISED IN {name or \"anonymous\"}')\n",
    "    print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './Data'\n",
    "\n",
    "class DataBlock(Enum):\n",
    "    TRAIN = 1\n",
    "    TEST = 2\n",
    "    BOTH = 3\n",
    "\n",
    "\n",
    "def load_stock_data(stock_id: int, directory: str) -> pd.DataFrame:\n",
    "    return pd.read_parquet(os.path.join(DATA_DIR, 'optiver-realized-volatility-prediction', directory, f'stock_id={stock_id}'))\n",
    "\n",
    "\n",
    "def load_data(stock_id: int, stem: str, block: DataBlock) -> pd.DataFrame:\n",
    "    if block == DataBlock.TRAIN:\n",
    "        return load_stock_data(stock_id, f'{stem}_train.parquet')\n",
    "    elif block == DataBlock.TEST:\n",
    "        return load_stock_data(stock_id, f'{stem}_test.parquet')\n",
    "    else:\n",
    "        return pd.concat([\n",
    "            load_data(stock_id, stem, DataBlock.TRAIN),\n",
    "            load_data(stock_id, stem, DataBlock.TEST)\n",
    "        ]).reset_index(drop=True)\n",
    "\n",
    "def load_book(stock_id: int, block: DataBlock=DataBlock.TRAIN) -> pd.DataFrame:\n",
    "    return load_data(stock_id, 'book', block)\n",
    "\n",
    "\n",
    "def load_trade(stock_id: int, block=DataBlock.TRAIN) -> pd.DataFrame:\n",
    "    return load_data(stock_id, 'trade', block)\n",
    "\n",
    "\n",
    "def calc_wap1(df: pd.DataFrame) -> pd.Series:\n",
    "    wap = (df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1']) / (df['bid_size1'] + df['ask_size1'])\n",
    "    return wap\n",
    "\n",
    "\n",
    "def calc_wap2(df: pd.DataFrame) -> pd.Series:\n",
    "    wap = (df['bid_price2'] * df['ask_size2'] + df['ask_price2'] * df['bid_size2']) / (df['bid_size2'] + df['ask_size2'])\n",
    "    return wap\n",
    "\n",
    "\n",
    "def realized_volatility(series):\n",
    "    return np.sqrt(np.sum(series**2))\n",
    "\n",
    "\n",
    "def log_return(series: np.ndarray):\n",
    "    return np.log(series).diff()\n",
    "\n",
    "\n",
    "def log_return_df2(series: np.ndarray):\n",
    "    return np.log(series).diff(2)\n",
    "\n",
    "\n",
    "def flatten_name(prefix, src_names):\n",
    "    ret = []\n",
    "    for c in src_names:\n",
    "        if c[0] in ['time_id', 'stock_id']:\n",
    "            ret.append(c[0])\n",
    "        else:\n",
    "            ret.append('.'.join([prefix] + list(c)))\n",
    "    return ret\n",
    "\n",
    "\n",
    "def make_book_feature(stock_id, block = DataBlock.TRAIN):\n",
    "    book = load_book(stock_id, block)\n",
    "\n",
    "    book['wap1'] = calc_wap1(book)\n",
    "    book['wap2'] = calc_wap2(book)\n",
    "    book['log_return1'] = book.groupby(['time_id'])['wap1'].apply(log_return)\n",
    "    book['log_return2'] = book.groupby(['time_id'])['wap2'].apply(log_return)\n",
    "    book['log_return_ask1'] = book.groupby(['time_id'])['ask_price1'].apply(log_return)\n",
    "    book['log_return_ask2'] = book.groupby(['time_id'])['ask_price2'].apply(log_return)\n",
    "    book['log_return_bid1'] = book.groupby(['time_id'])['bid_price1'].apply(log_return)\n",
    "    book['log_return_bid2'] = book.groupby(['time_id'])['bid_price2'].apply(log_return)\n",
    "\n",
    "    book['wap_balance'] = abs(book['wap1'] - book['wap2'])\n",
    "    book['price_spread'] = (book['ask_price1'] - book['bid_price1']) / ((book['ask_price1'] + book['bid_price1']) / 2)\n",
    "    book['bid_spread'] = book['bid_price1'] - book['bid_price2']\n",
    "    book['ask_spread'] = book['ask_price1'] - book['ask_price2']\n",
    "    book['total_volume'] = (book['ask_size1'] + book['ask_size2']) + (book['bid_size1'] + book['bid_size2'])\n",
    "    book['volume_imbalance'] = abs((book['ask_size1'] + book['ask_size2']) - (book['bid_size1'] + book['bid_size2']))\n",
    "    \n",
    "    features = {\n",
    "        'seconds_in_bucket': ['count'],\n",
    "        'wap1': [np.sum, np.mean, np.std],\n",
    "        'wap2': [np.sum, np.mean, np.std],\n",
    "        'log_return1': [np.sum, realized_volatility, np.mean, np.std],\n",
    "        'log_return2': [np.sum, realized_volatility, np.mean, np.std],\n",
    "        'log_return_ask1': [np.sum, realized_volatility, np.mean, np.std],\n",
    "        'log_return_ask2': [np.sum, realized_volatility, np.mean, np.std],\n",
    "        'log_return_bid1': [np.sum, realized_volatility, np.mean, np.std],\n",
    "        'log_return_bid2': [np.sum, realized_volatility, np.mean, np.std],\n",
    "        'wap_balance': [np.sum, np.mean, np.std],\n",
    "        'price_spread':[np.sum, np.mean, np.std],\n",
    "        'bid_spread':[np.sum, np.mean, np.std],\n",
    "        'ask_spread':[np.sum, np.mean, np.std],\n",
    "        'total_volume':[np.sum, np.mean, np.std],\n",
    "        'volume_imbalance':[np.sum, np.mean, np.std]\n",
    "    }\n",
    "    \n",
    "    agg = book.groupby('time_id').agg(features).reset_index(drop=False)\n",
    "    agg.columns = flatten_name('book', agg.columns)\n",
    "    agg['stock_id'] = stock_id\n",
    "    \n",
    "    for time in [450, 300, 150]:\n",
    "        d = book[book['seconds_in_bucket'] >= time].groupby('time_id').agg(features).reset_index(drop=False)\n",
    "        d.columns = flatten_name(f'book_{time}', d.columns)\n",
    "        agg = pd.merge(agg, d, on='time_id', how='left')\n",
    "    return agg\n",
    "\n",
    "\n",
    "def make_trade_feature(stock_id, block = DataBlock.TRAIN):\n",
    "    trade = load_trade(stock_id, block)\n",
    "    trade['log_return'] = trade.groupby('time_id')['price'].apply(log_return)\n",
    "\n",
    "    features = {\n",
    "        'log_return':[realized_volatility],\n",
    "        'seconds_in_bucket':['count'],\n",
    "        'size':[np.sum],\n",
    "        'order_count':[np.mean],\n",
    "    }\n",
    "\n",
    "    agg = trade.groupby('time_id').agg(features).reset_index()\n",
    "    agg.columns = flatten_name('trade', agg.columns)\n",
    "    agg['stock_id'] = stock_id\n",
    "        \n",
    "    for time in [450, 300, 150]:\n",
    "        d = trade[trade['seconds_in_bucket'] >= time].groupby('time_id').agg(features).reset_index(drop=False)\n",
    "        d.columns = flatten_name(f'trade_{time}', d.columns)\n",
    "        agg = pd.merge(agg, d, on='time_id', how='left')\n",
    "    return agg\n",
    "\n",
    "\n",
    "def make_book_feature_v2(stock_id, block = DataBlock.TRAIN):\n",
    "    book = load_book(stock_id, block)\n",
    "\n",
    "    prices = book.set_index('time_id')[['bid_price1', 'ask_price1', 'bid_price2', 'ask_price2']]\n",
    "    time_ids = list(set(prices.index))\n",
    "\n",
    "    ticks = {}\n",
    "    for tid in time_ids:\n",
    "        try:\n",
    "            price_list = prices.loc[tid].values.flatten()\n",
    "            price_diff = sorted(np.diff(sorted(set(price_list))))\n",
    "            ticks[tid] = price_diff[0]\n",
    "        except Exception:\n",
    "            print_trace(f'tid={tid}')\n",
    "            ticks[tid] = np.nan\n",
    "        \n",
    "    dst = pd.DataFrame()\n",
    "    dst['time_id'] = np.unique(book['time_id'])\n",
    "    dst['stock_id'] = stock_id\n",
    "    dst['tick_size'] = dst['time_id'].map(ticks)\n",
    "\n",
    "    return dst\n",
    "\n",
    "\n",
    "def make_features(base, block):\n",
    "    stock_ids = set(base['stock_id'])\n",
    "    with timer('books'):\n",
    "        books = Parallel(n_jobs=-1)(delayed(make_book_feature)(i, block) for i in stock_ids)\n",
    "        book = pd.concat(books)\n",
    "\n",
    "    with timer('trades'):\n",
    "        trades = Parallel(n_jobs=-1)(delayed(make_trade_feature)(i, block) for i in stock_ids)\n",
    "        trade = pd.concat(trades)\n",
    "\n",
    "    with timer('extra features'):\n",
    "        df = pd.merge(base, book, on=['stock_id', 'time_id'], how='left')\n",
    "        df = pd.merge(df, trade, on=['stock_id', 'time_id'], how='left')\n",
    "        #df = make_extra_features(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_features_v2(base, block):\n",
    "    stock_ids = set(base['stock_id'])\n",
    "    with timer('books(v2)'):\n",
    "        books = Parallel(n_jobs=-1)(delayed(make_book_feature_v2)(i, block) for i in stock_ids)\n",
    "        book_v2 = pd.concat(books)\n",
    "\n",
    "    d = pd.merge(base, book_v2, on=['stock_id', 'time_id'], how='left')\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[load feather]  0.374sec\n",
      "is 1st stage\n",
      "[books]  4.024sec\n",
      "[trades]  0.215sec\n",
      "[extra features]  0.011sec\n",
      "[books(v2)]  0.201sec\n",
      "(428932, 216)\n",
      "(3, 216)\n"
     ]
    }
   ],
   "source": [
    "#stock_id_list = os.listdir(os.path.join(DATA_DIR, 'optiver-realized-volatility-prediction/book_train.parquet'))\n",
    "#stock_id_list = [int(x[9:]) for x in stock_id_list]\n",
    "train = pd.read_csv(os.path.join(DATA_DIR, 'optiver-realized-volatility-prediction', 'train.csv'))\n",
    "stock_ids = set(train['stock_id'])\n",
    "\n",
    "if USE_PRECOMPUTE_FEATURES:\n",
    "    with timer('load feather'):\n",
    "        df = pd.read_feather(os.path.join(DATA_DIR, 'optiver-df2', 'features_v2.f'))\n",
    "else:\n",
    "    df = make_features(train, DataBlock.TRAIN)\n",
    "    # v2\n",
    "    df = make_features_v2(df, DataBlock.TRAIN)\n",
    "\n",
    "df.to_feather('./Data/optiver-df2/features_v2.f')  # save cache\n",
    "\n",
    "test = pd.read_csv(os.path.join(DATA_DIR, 'optiver-realized-volatility-prediction', 'test.csv'))\n",
    "if len(test) == 3:\n",
    "    print('is 1st stage')\n",
    "    IS_1ST_STAGE = True\n",
    "\n",
    "if IS_1ST_STAGE and MEMORY_TEST_MODE:\n",
    "    print('use copy of training data as test data to immitate 2nd stage RAM usage.')\n",
    "    test_df = df.iloc[:170000].copy()\n",
    "    test_df['time_id'] += 32767\n",
    "    test_df['row_id'] = ''\n",
    "else:\n",
    "    test_df = make_features(test, DataBlock.TEST)\n",
    "    test_df = make_features_v2(test_df, DataBlock.TEST)\n",
    "\n",
    "print(df.shape)\n",
    "print(test_df.shape)\n",
    "df = pd.concat([df, test_df.drop('row_id', axis=1)]).reset_index(drop=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('NLP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d49957daa954e6bec9f177fc046718ee074770fab86eb9520507fb7fbdbef1cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
